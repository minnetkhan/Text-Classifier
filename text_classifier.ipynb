{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    importing all files...\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os, nltk, unicodedata, string, re, pickle\n",
    "from sys import getsizeof\n",
    "import math\n",
    "\n",
    "import normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    importing trained model and test file\n",
    "'''\n",
    "pickle_file = open(\"training/pickled_model\", \"rb\")\n",
    "model = pickle.load(pickle_file)\n",
    "pickle_file.close()\n",
    "class_mapping_index, class_docs_count, total_docs, class_prob, \\\n",
    "count_each_word_frequency_in_each_class, total_words_in_each_class, total_vocabulary = model\n",
    "\n",
    "input_file = open(\"testing/input.txt\", \"r\", errors='ignore')\n",
    "test_data = input_file.read()\n",
    "input_file.close()\n",
    "test_data = normalization.normalize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-f112fe1544b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount_each_word_frequency_in_each_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mfreq_of_word_in_a_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_each_word_frequency_in_each_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mfreq_of_word_in_a_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "add_k_smoothing = [1, 5, 10, 100]\n",
    "\n",
    "prob_of_each_class = [[0 for j in range(0, 4)] for i in range(0, 20) ]\n",
    "\n",
    "for class_index, count_each_word_frequency_in_each_class in enumerate(count_each_word_frequency_in_each_class):\n",
    "        total_words_in_a_class = total_words_in_each_class[class_index]\n",
    "\n",
    "        for word in test_data:\n",
    "            if word in count_each_word_frequency_in_each_class:\n",
    "                freq_of_word_in_a_class = count_each_word_frequency_in_each_class[word]\n",
    "            else:\n",
    "                freq_of_word_in_a_class = 0\n",
    "\n",
    "            for index, smoothing_factor in enumerate(add_k_smoothing):\n",
    "                log_value = math.log10((freq_of_word_in_a_class+smoothing_factor)/\n",
    "                                   (total_words_in_a_class+(smoothing_factor*total_vocabulary)))\n",
    "\n",
    "                prob_of_each_class[class_index][index] += log_value\n",
    "\n",
    "                \n",
    "                \n",
    "for smoothing_index, smoothing_factor in enumerate(add_k_smoothing):\n",
    "    max = prob_of_each_class[0][smoothing_index]\n",
    "    class_name = 100\n",
    "    print(\"probabilities after add\", smoothing_factor, \"smoothing\")\n",
    "    print(\"class_name\\t\\t\\t\", \"class_probability\")\n",
    "    for class_index, prob in enumerate(prob_of_each_class):\n",
    "        print(class_mapping_index[class_index][0], \"\\t\\t\\t\",prob[smoothing_index])\n",
    "        if prob[0] >= max:\n",
    "            max = prob[0]\n",
    "            class_name = class_index\n",
    "            \n",
    "    print(\"\\n\\n\")\n",
    "    print(\"maximum prob: \", prob_of_each_class[class_name][0], \n",
    "          \"\\ntext belongs to class: \", class_mapping_index[class_name][0])\n",
    "    \n",
    "    print(\"*********************************************************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
